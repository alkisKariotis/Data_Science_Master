{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0c1765-0874-4ec1-bc0e-a10a3490e161",
   "metadata": {},
   "source": [
    "# Face Detector | Mask Detector with Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968949d-c028-4296-94c2-3d062e28c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define class for Mask and Face Detector\n",
    "class MaskAndFaceDetector:\n",
    "    # Initializer/Constructor for the class\n",
    "    def __init__(self):\n",
    "        # Load mask classifier model\n",
    "        self.mask_classifier = self._load_trained_model('model2-013.model')\n",
    "        # Load face classifier model\n",
    "        self.face_classifier = self._load_trained_model('face_detection_model.h5')\n",
    "        \n",
    "        # Define labels dictionary\n",
    "        self.label_dict = {0:'No Mask', 1:'Mask'}\n",
    "        # Define colors dictionary to represent mask/no mask situation\n",
    "        self.color_dict = {0:(0,0,255), 1:(0,255,0)}\n",
    "        \n",
    "        # Define scale for face detection\n",
    "        self.scale = 4\n",
    "        # Load pre-trained face detector model from OpenCV\n",
    "        self.face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Method to load model from the path\n",
    "    def _load_trained_model(self, model_path):\n",
    "        return load_model(model_path)\n",
    "\n",
    "    # Method to prepare face for mask classification\n",
    "    def _prepare_face(self, face_frame):\n",
    "        # Resize face to the size model was trained on\n",
    "        resized_face = cv2.resize(face_frame, (150,150))\n",
    "        # Normalize pixel values\n",
    "        normalized_face = resized_face / 255.0\n",
    "        # Reshape face in a way model expects it\n",
    "        reshaped_face = np.reshape(normalized_face, (1,150,150,3))\n",
    "        reshaped_face = np.vstack([reshaped_face])\n",
    "        \n",
    "        return reshaped_face\n",
    "\n",
    "    # Method to prepare face for face detection model\n",
    "    def _prepare_face_for_face_detection(self, frame):\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize face to the size model was trained on\n",
    "        face_image = cv2.resize(gray, (64, 64))\n",
    "        # Reshape and normalize image\n",
    "        face_image = np.reshape(face_image, (1, 64, 64, 1))\n",
    "        face_image = face_image / 255.0\n",
    "        \n",
    "        return face_image\n",
    "\n",
    "    # Method to perform face and mask detection in a video feed\n",
    "    def detect_mask_and_face_in_video_feed(self):\n",
    "        # Start video capture\n",
    "        video = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Start loop to continuously capture video frames\n",
    "        while True:\n",
    "            # Capture video frame\n",
    "            ret, frame = video.read()\n",
    "            # Flip frame horizontally\n",
    "            frame = cv2.flip(frame, 1, 1)\n",
    "            # Resize frame for face detection\n",
    "            small_frame = cv2.resize(frame, (frame.shape[1] // self.scale, frame.shape[0] // self.scale))\n",
    "            # Perform face detection\n",
    "            faces = self.face_detector.detectMultiScale(small_frame)\n",
    "            \n",
    "            # Loop over all detected faces\n",
    "            for face in faces:\n",
    "                # Get face coordinates and size\n",
    "                x, y, w, h = [v * self.scale for v in face]\n",
    "                # Get face frame\n",
    "                face_frame = frame[y:y+h, x:x+w]\n",
    "                # Prepare face for mask classification\n",
    "                processed_face = self._prepare_face(face_frame)\n",
    "                \n",
    "                # Perform mask classification\n",
    "                pred = self.mask_classifier.predict(processed_face)\n",
    "                # Get classification result\n",
    "                pred_result = np.argmax(pred, axis=1)[0]\n",
    "                \n",
    "                # Draw rectangle around face based on mask/no mask\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), self.color_dict[pred_result], 2)\n",
    "                cv2.rectangle(frame, (x, y-40), (x+w, y), self.color_dict[pred_result], -1)\n",
    "                cv2.putText(frame, self.label_dict[pred_result], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "                # Prepare face for face detection\n",
    "                face_frame_face_detection = self._prepare_face_for_face_detection(face_frame)\n",
    "                # Perform face detection\n",
    "                face_detection_pred = self.face_classifier.predict(face_frame_face_detection)\n",
    "                \n",
    "                # Define text location\n",
    "                text_location = (frame.shape[1] - 200, 50)  # adjust the values as needed\n",
    "\n",
    "                # Put text based on face detection result\n",
    "                if face_detection_pred > 0.5:\n",
    "                    cv2.putText(frame, 'Face', text_location, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, 'No Face', text_location, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "            # Show video frame with detections\n",
    "            cv2.imshow('MASK AND FACE DETECTOR', frame)\n",
    "            \n",
    "            # Break the loop on 'ESC' press\n",
    "            if cv2.waitKey(10) == 27:\n",
    "                break\n",
    "                \n",
    "        # Release video capture object and destroy windows\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Main function to start detection\n",
    "def main():\n",
    "    # Create detector object\n",
    "    detector = MaskAndFaceDetector()\n",
    "    # Perform detection\n",
    "    detector.detect_mask_and_face_in_video_feed()\n",
    "\n",
    "# Call main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67a2c5-16b7-4653-89ee-e1fb398d293e",
   "metadata": {},
   "source": [
    "# Face Detector alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da07ef-3560-4794-b8f7-4f28385ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the trained model\n",
    "# model = load_model('face_detection_model.h5')\n",
    "\n",
    "# # Function to perform real-time face detection\n",
    "# def detect_faces(frame):\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     face_image = cv2.resize(gray, (64, 64))\n",
    "#     face_image = np.reshape(face_image, (1, 64, 64, 1))\n",
    "#     face_image = face_image / 255.0\n",
    "#     prediction = model.predict(face_image)\n",
    "#     if prediction > 0.5:\n",
    "#         cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 255, 0), 2)\n",
    "#         cv2.putText(frame, 'Face', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "#     else:\n",
    "#         cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, 'No Face', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "#     return frame\n",
    "\n",
    "# # Open the webcam\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# # Process the video frames in real-time\n",
    "# while True:\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = video_capture.read()\n",
    "    \n",
    "#     # Perform face detection\n",
    "#     output_frame = detect_faces(frame)\n",
    "    \n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow('Face Detection', output_frame)\n",
    "    \n",
    "#     # Exit if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
